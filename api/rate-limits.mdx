---
title: "Rate Limits"
sidebarTitle: "Rate Limits"
description: "Understanding API rate limits and best practices"
---

## Overview

The Toku API implements rate limiting to ensure fair usage and maintain service stability for all users. Rate limits are applied per API key.

## Rate Limit Tiers

| Tier | Requests per Minute | Requests per Hour |
|------|---------------------|-------------------|
| Standard | 60 | 1,000 |
| Premium | 300 | 10,000 |
| Enterprise | Custom | Custom |

Contact your Toku account representative to discuss rate limit increases for high-volume integrations.

## Rate Limit Headers

API responses include headers to help you track your rate limit status:

| Header | Description |
|--------|-------------|
| `X-RateLimit-Limit` | Maximum requests allowed in the current window |
| `X-RateLimit-Remaining` | Requests remaining in the current window |
| `X-RateLimit-Reset` | Unix timestamp when the rate limit resets |

## Handling Rate Limits

When you exceed the rate limit, the API returns a `429 Too Many Requests` response:

```json
{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Too many requests. Please retry after 60 seconds.",
    "details": {
      "retryAfter": 60
    }
  }
}
```

### Implementing Exponential Backoff

We recommend implementing exponential backoff for handling rate limits:

```javascript
async function makeRequestWithRetry(url, options, maxRetries = 3) {
  let delay = 1000; // Start with 1 second

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);

      if (response.status === 429) {
        if (attempt === maxRetries) {
          throw new Error('Rate limit exceeded. Max retries reached.');
        }

        const retryAfter = response.headers.get('Retry-After') || delay / 1000;
        await sleep(retryAfter * 1000);
        delay *= 2; // Exponential backoff
        continue;
      }

      return response;
    } catch (error) {
      if (attempt === maxRetries) throw error;
      await sleep(delay);
      delay *= 2;
    }
  }
}

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}
```

### Python Example

```python
import time
import requests

def make_request_with_retry(url, headers, data=None, max_retries=3):
    delay = 1  # Start with 1 second

    for attempt in range(max_retries + 1):
        response = requests.post(url, headers=headers, json=data) if data else requests.get(url, headers=headers)

        if response.status_code == 429:
            if attempt == max_retries:
                raise Exception('Rate limit exceeded. Max retries reached.')

            retry_after = int(response.headers.get('Retry-After', delay))
            time.sleep(retry_after)
            delay *= 2
            continue

        return response

    raise Exception('Max retries exceeded')
```

## Best Practices

<CardGroup cols={2}>
  <Card title="Batch Requests" icon="layer-group">
    Combine multiple operations into single requests where possible
  </Card>
  <Card title="Cache Responses" icon="database">
    Cache frequently-accessed data like currency lists and org details
  </Card>
  <Card title="Monitor Usage" icon="chart-line">
    Track your API usage to stay within limits
  </Card>
  <Card title="Use Webhooks" icon="bell">
    Use webhooks instead of polling for status updates
  </Card>
</CardGroup>

## Optimizing API Usage

### Do

- **Cache static data**: Currency lists and organization details rarely change
- **Use pagination**: Request only the data you need
- **Batch operations**: Group related operations when possible
- **Implement retries**: Use exponential backoff for transient failures

### Don't

- **Poll frequently**: Avoid checking status every few seconds
- **Ignore headers**: Monitor rate limit headers to avoid hitting limits
- **Retry immediately**: Always wait before retrying failed requests
- **Make redundant calls**: Cache data that doesn't change frequently

## Need Higher Limits?

If your integration requires higher rate limits:

1. Review your implementation for optimization opportunities
2. Contact your Toku account representative
3. Provide details about your expected API volume
4. Discuss Enterprise tier options for custom limits
